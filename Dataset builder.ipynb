{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowers image dataset tool notebook\n",
    "\n",
    "This notebook is used to rearrange original flowers image dataset and to create a new one, copy of source, but with different sets (train, validation and test) size.\n",
    "\n",
    "Original PyTorch Scholarship Challenge dataset is available [here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip)\n",
    "\n",
    "\n",
    "## Two options available:\n",
    "- **OPTION 1** Create a new dataset with specific sets size (percentage of total source dataset) for train, validation and test. Optionally is possible to create a new balanced dataset, with the same quantity of items foreach class.\n",
    "\n",
    "- **OPTION 2** Create a copy of source dataset preserving original train, validation and test contents but with balanced number of items foreach class.\n",
    "\n",
    "\n",
    "\n",
    "**Feel free to change this notebook according to your needs. Code is not optimized, but it works! :) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source root folder where \"train\", \"valid\" and \"test\" subfolders are located. \n",
    "data_folder = 'flower_data'\n",
    "# Destination root folder where new sets of images will be copied.\n",
    "new_folder  = 'new_flowers'\n",
    "\n",
    "# PLEASE SELECT HOW TO CREATE NEW DATASET - UNCOMMENT ONE OF FOLLOWING \n",
    "#option = 1       \n",
    "option = 2      \n",
    "\n",
    "######## Option 1 only:\n",
    "# Create a new dataset with specific sets size (percentage of total source dataset) for train, validation and test.\n",
    "# Optionally is possible to create a new balanced dataset, with the same quantity of items foreach class.\n",
    "\n",
    "# Percentage of each set\n",
    "train_size = 0.8    # 80%\n",
    "valid_size = 0.1    # 10%\n",
    "test_size  = 0.1    # 10%\n",
    "\n",
    "# Set to True if new dataset needs to be class balanced. \n",
    "class_balanced = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which method?\n",
    "if 'option' not in locals():\n",
    "    raise Exception(\"PLEASE SELECT HOW TO CREATE NEW DATASET!\") \n",
    "if option not in [1,2]:\n",
    "    raise Exception(\"Method '{}' unknow!\".format(option)) \n",
    "    \n",
    "# Check folders! Destination folder must not exists! (safe) \n",
    "if os.path.isdir(data_folder) == False:\n",
    "    raise Exception(\"Source folder not found!\")\n",
    "if os.path.isdir(new_folder) == True:\n",
    "    raise Exception(\"Destination folder exists!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods implementation. Nothing to be set after this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are used to load contents from source folder and \n",
    "# save data to a Dataframe\n",
    "# Image count (foreach set) is printed\n",
    "def get_contents(path, data):\n",
    "    for folder in sorted(os.listdir(path)):\n",
    "        if (os.path.isdir(os.path.join(path, folder))):\n",
    "            get_contents(os.path.join(path, folder), data)\n",
    "        else:\n",
    "            data.append((path, folder))\n",
    "    \n",
    "def get_set(path):\n",
    "    setname = ''\n",
    "    if path.find('valid') > -1:\n",
    "        setname = 'valid'\n",
    "    elif path.find('test') > -1:\n",
    "        setname = 'test'\n",
    "    elif path.find('train') > -1:\n",
    "        setname = 'train'\n",
    "    return setname   \n",
    "\n",
    "def get_data(folder):\n",
    "    data = []\n",
    "    get_contents(folder, data)\n",
    "    df = pd.DataFrame(data, columns=['Folder', 'File'])\n",
    "    df['Class'] = df.apply(lambda row: os.path.basename(os.path.normpath(row['Folder'])), axis=1) \n",
    "    df['Set'] = df.apply(lambda row: get_set(row['Folder']), axis=1)\n",
    "\n",
    "    for s in ['train','valid','test']:\n",
    "        print('** {} Set **'.format(s.title()))\n",
    "        ds = df[df['Set'] == s]\n",
    "        print('Items: {} - Classes: {}'.format(ds.shape[0], ds['Class'].unique().size))\n",
    "        da = ds[['File','Class']].groupby(['Class']).agg(['count'])\n",
    "        print('Min items per class: {}'.format(da.min()[0]))\n",
    "        print('Max items per class: {}'.format(da.max()[0]))\n",
    "        print('')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Train Set **\n",
      "Items: 6552 - Classes: 102\n",
      "Min items per class: 27\n",
      "Max items per class: 206\n",
      "\n",
      "** Valid Set **\n",
      "Items: 818 - Classes: 102\n",
      "Min items per class: 1\n",
      "Max items per class: 28\n",
      "\n",
      "** Test Set **\n",
      "Items: 0 - Classes: 0\n",
      "Min items per class: nan\n",
      "Max items per class: nan\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Class</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_data\\train\\1</td>\n",
       "      <td>image_06734.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flower_data\\train\\1</td>\n",
       "      <td>image_06735.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flower_data\\train\\1</td>\n",
       "      <td>image_06736.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flower_data\\train\\1</td>\n",
       "      <td>image_06737.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flower_data\\train\\1</td>\n",
       "      <td>image_06738.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Folder             File Class    Set\n",
       "0  flower_data\\train\\1  image_06734.jpg     1  train\n",
       "1  flower_data\\train\\1  image_06735.jpg     1  train\n",
       "2  flower_data\\train\\1  image_06736.jpg     1  train\n",
       "3  flower_data\\train\\1  image_06737.jpg     1  train\n",
       "4  flower_data\\train\\1  image_06738.jpg     1  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load contents\n",
    "df = get_data(data_folder)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 specific methods.\n",
    "# get_slice breaks filelist in three sets according to provided percentage\n",
    "# items_count (if set) is used to create balanced dataset\n",
    "def get_slice(filelist, train = 0.8, valid = 0.1, test = 0.1, items_count = 0):\n",
    "    if items_count > 0:\n",
    "        filecount = items_count\n",
    "    else:\n",
    "        filecount = len(filelist)\n",
    "        \n",
    "    train = int(filecount * train)\n",
    "    valid = int(filecount * valid)\n",
    "    test = filecount - train - valid\n",
    "    \n",
    "    train_list = random.sample(filelist, train)\n",
    "    for i in train_list:\n",
    "        filelist.remove(i)\n",
    "        \n",
    "    valid_list = random.sample(filelist, valid)\n",
    "    for i in valid_list:\n",
    "        filelist.remove(i)\n",
    "      \n",
    "    test_list = random.sample(filelist, test)\n",
    "    return train_list, valid_list, test_list \n",
    "\n",
    "# main option 1 method. Rearrange original images in three new sets (train, validation, test)\n",
    "# optionally class balanced\n",
    "def rearrange(df, root_path, train_size = 0.8, valid_size = 0.1, test_size = 0.1, balanced = False):\n",
    "    if balanced:\n",
    "        min_class_items = df[['File','Class']].groupby(['Class']).agg(['count']).min()[0]\n",
    "    else:\n",
    "        min_class_items = 0\n",
    "    df2 = df.set_index('File')\n",
    "    df2['NewFolder'], df2['NewSet'] = '',''\n",
    "\n",
    "    for c in df['Class'].unique():\n",
    "        train, valid, test = get_slice(df[df['Class'] == c]['File'].tolist(), \n",
    "                                       train = train_size, valid = valid_size, test = test_size, \n",
    "                                       items_count = min_class_items)\n",
    "        for f in train:\n",
    "            df2.loc[f,['NewFolder','NewSet']] = [os.path.join(root_path, 'train' , c), 'train']\n",
    "        for f in valid:\n",
    "            df2.loc[f,['NewFolder','NewSet']] = [os.path.join(root_path, 'valid', c), 'valid']\n",
    "        for f in test:\n",
    "            df2.loc[f,['NewFolder','NewSet']] = [os.path.join(root_path, 'test', c), 'test']            \n",
    "        \n",
    "    return df2.reset_index()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 specific method with max number of files!\n",
    "# Foreach original set, get class with higher file count and balance number of images of other classes by adding random\n",
    "# copies of files from the same set. (This is an implementation of oversampling.)\n",
    "\n",
    "def set_balance(df, root_path):\n",
    "    df2 = df.set_index('File')\n",
    "    df2['NewFolder'], df2['NewSet'] = '',''\n",
    "    \n",
    "    df3 = pd.DataFrame(data=None, columns = ['File', 'Folder', 'Class', 'Set', 'NewFolder', 'NewSet', 'NewFile'])\n",
    "\n",
    "    for s in ['train', 'valid', 'test']:\n",
    "        r = df[df['Set'] == s]\n",
    "        max_class_items = r[['File','Class']].groupby(['Class']).agg(['count']).max()[0]\n",
    "        for c in r['Class'].unique():\n",
    "            filelist = r[r['Class'] == c]['File'].tolist() \n",
    "            #selected = random.sample(filelist, min_class_items)\n",
    "            for f in filelist:\n",
    "                df2.loc[f,['NewFolder','NewSet']] = [os.path.join(root_path, s , c), s]\n",
    "                       \n",
    "            \n",
    "            selected = filelist.copy()\n",
    "            for i in np.random.choice(filelist, size=max_class_items-len(filelist), replace=True).tolist():\n",
    "                selected.append(i)\n",
    "            \n",
    "            if s =='train':\n",
    "                for num,f in list(enumerate(selected)):\n",
    "                    df3 = df3.append(pd.DataFrame([[f, df2.loc[f]['Folder'], df2.loc[f]['Class'],\n",
    "                                                df2.loc[f]['Set'], df2.loc[f]['NewFolder'], df2.loc[f]['NewSet'],\n",
    "                                                f[:-4] + f'_copy{num+1}.jpg']], columns=df3.columns), ignore_index=True)\n",
    "            else:\n",
    "                 for f in filelist:\n",
    "                        df3 = df3.append(pd.DataFrame([[f, df2.loc[f]['Folder'], df2.loc[f]['Class'],\n",
    "                                                df2.loc[f]['Set'], df2.loc[f]['NewFolder'],\n",
    "                                                df2.loc[f]['NewSet'], f]], columns=df3.columns), ignore_index=True)\n",
    "            \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy file method. Dataframe is used to get source filename and new destination folder\n",
    "def copy_files(df):\n",
    "    for index, row in df[df['NewFolder'] != ''].iterrows():\n",
    "        if not os.path.exists(row['NewFolder']):\n",
    "            os.makedirs(row['NewFolder'])\n",
    "        copyfile(os.path.join(row['Folder'], row['File']), \n",
    "                 os.path.join(row['NewFolder'], row['NewFile']))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 or 2? \n",
    "if option == 1:\n",
    "    df_new = rearrange(df, new_folder, \n",
    "                   train_size = train_size, valid_size = valid_size, test_size = test_size, \n",
    "                   balanced = class_balanced)\n",
    "else:\n",
    "    df_new = set_balance(df, new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files!\n",
    "copy_files(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS: NEW DATASET CONTENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Train Set **\n",
      "Items: 21012 - Classes: 102\n",
      "Min items per class: 206\n",
      "Max items per class: 206\n",
      "\n",
      "** Valid Set **\n",
      "Items: 818 - Classes: 102\n",
      "Min items per class: 1\n",
      "Max items per class: 28\n",
      "\n",
      "** Test Set **\n",
      "Items: 0 - Classes: 0\n",
      "Min items per class: nan\n",
      "Max items per class: nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New dataset items count\n",
    "df2 = get_data(new_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
