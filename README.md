# Content: PyTorch Framework
## Project: Flowers Classification

### Install

This project requires **Python 3.7** and the following Python libraries installed:

- [torch](https://pytorch.org/get-started/locally/)
- [torchvision](https://pytorch.org/docs/0.3.0/torchvision/index.html)
- [NumPy](http://www.numpy.org/)
- [matplotlib](http://matplotlib.org/)
- [scikit-learn](http://scikit-learn.org/stable/)
- [seaborn](https://seaborn.pydata.org/)
- [json](https://docs.python.org/3/library/json.html)
- [Image](https://pillow.readthedocs.io/en/stable/reference/Image.html)

You will also need to have software installed to run and execute a [Jupyter Notebook](http://ipython.org/notebook.html)

If you do not have Python installed yet, it is highly recommended that you install the [Anaconda](http://continuum.io/downloads) distribution of Python, which already has some of the above packages and more included.

### Code

Code is provided in the `Image Classifier Project_Resnet152_newflowers.ipynb` notebook file. If you are interested in how the parameters influence the outcome, please feel free to explore this Python file.

### Run

In a terminal or command window, navigate to the top-level project directory `pytorch_challenge/` (that contains this README) and run one of the following commands:

```bash
ipython notebook Project_Resnet152_newflowers.ipynb
```  
or
```bash
jupyter notebook Project_Resnet152_newflowers.ipynb
```

This will open the Jupyter Notebook software and project file in your browser.

### Project overview

You will build an image classifier from scratch that will identify different species of flowers.

### Data

The data set contains around 7000 images of flowers from 102 different species. The provided images were split into a training set and a validation set. You can [download the images from here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip) as a zipped archive. Just uncompress it and you should be good to go.


### Results
It was possible to obtain an accuracy of 98.9% using a pretrained Resnet 152 model on the provided validation set with after 27 epochs (18 epochs with only the classifier parameters unfrozen and 9 with all model parameters unfrozen).